diff --git a/pyfr/plugins/__init__.py b/pyfr/plugins/__init__.py
index 3de3c10..500a070 100644
--- a/pyfr/plugins/__init__.py
+++ b/pyfr/plugins/__init__.py
@@ -1,6 +1,7 @@
 # -*- coding: utf-8 -*-
 
 from pyfr.plugins.base import BasePlugin
+from pyfr.plugins.controller import ControllerPlugin
 from pyfr.plugins.dtstats import DtStatsPlugin
 from pyfr.plugins.fluidforce import FluidForcePlugin
 from pyfr.plugins.nancheck import NaNCheckPlugin
diff --git a/pyfr/plugins/controller.py b/pyfr/plugins/controller.py
new file mode 100644
index 0000000..5f5b880
--- /dev/null
+++ b/pyfr/plugins/controller.py
@@ -0,0 +1,349 @@
+# -*- coding: utf-8 -*-
+import glob
+import h5py
+import json
+import numpy as np
+import os, sys
+import subprocess
+import tensorflow as tf
+import argparse
+
+from cvxpy import *
+from builtins import min
+from builtins import max
+from koopman_model import KoopmanModel
+from pyfr.mpiutil import get_comm_rank_root, get_mpi
+from pyfr.plugins.base import BasePlugin
+
+
+def _closest_upts_bf(etypes, eupts, pts):
+    for p in pts:
+        # Compute the distances between each point and p
+        dists = [np.linalg.norm(e - p, axis=2) for e in eupts]
+
+        # Get the index of the closest point to p for each element type
+        amins = [np.unravel_index(np.argmin(d), d.shape) for d in dists]
+
+        # Dereference to get the actual distances and locations
+        dmins = [d[a] for d, a in zip(dists, amins)]
+        plocs = [e[a] for e, a in zip(eupts, amins)]
+
+        # Find the minimum across all element types
+        yield min(zip(dmins, plocs, etypes, amins))
+
+
+def _closest_upts_kd(etypes, eupts, pts):
+    from scipy.spatial import cKDTree
+
+    # Flatten the physical location arrays
+    feupts = [e.reshape(-1, e.shape[-1]) for e in eupts]
+
+    # For each element type construct a KD-tree of the upt locations
+    trees = [cKDTree(f) for f in feupts]
+
+    for p in pts:
+        # Query the distance/index of the closest upt to p
+        dmins, amins = zip(*[t.query(p) for t in trees])
+
+        # Unravel the indices
+        amins = [np.unravel_index(i, e.shape[:2])
+                 for i, e in zip(amins, eupts)]
+
+        # Dereference to obtain the precise locations
+        plocs = [e[a] for e, a in zip(eupts, amins)]
+
+        # Reduce across element types
+        yield min(zip(dmins, plocs, etypes, amins))
+
+
+def _closest_upts(etypes, eupts, pts):
+    try:
+        # Attempt to use a KD-tree based approach
+        yield from _closest_upts_kd(etypes, eupts, pts)
+    except ImportError:
+        # Otherwise fall back to brute force
+        yield from _closest_upts_bf(etypes, eupts, pts)
+
+
+class ControllerPlugin(BasePlugin):
+    name = 'controller'
+    systems = ['*']
+    formulations = ['dual', 'std']
+
+    def __init__(self, intg, cfgsect, suffix):
+        super().__init__(intg, cfgsect, suffix)
+
+        # Underlying elements class
+        self.elementscls = intg.system.elementscls
+
+        # Process frequency and other params
+        self.nsteps = self.cfg.getint(cfgsect, 'nsteps')
+        self.save_data = self.cfg.getint(cfgsect, 'savedata')
+        self.set_omega = self.cfg.getint(cfgsect, 'setomega')
+        self.perform_mpc = (self.cfg.getint(cfgsect, 'mpc') == 1)
+
+        # List of points to be sampled and format
+        self.pts = self.cfg.getliteral(cfgsect, 'samp-pts')
+        self.fmt = self.cfg.get(cfgsect, 'format', 'primitive')
+
+        # Define directory where solution snapshots should be saved
+        self.save_dir = self.cfg.getpath(cfgsect, 'save_dir')
+
+        # If performing mpc, then load network
+        if self.perform_mpc:
+
+            # Define checkpoint name
+            self.ckpt_name = self.cfg.get(cfgsect, 'checkpoint')
+
+            # Define directory containing training scripts
+            self.training_path = self.cfg.getpath(cfgsect, 'training_path')
+            sys.path.append(self.training_path)
+
+
+
+            # Define directory containing base flow solution
+            base_flow = self.cfg.getpath(cfgsect, 'base_flow')
+
+            # Set constraints for mpc
+            self.R = self.cfg.getfloat(cfgsect, 'R')
+            self.u_max = self.cfg.getfloat(cfgsect, 'u_max')
+
+            # Read in args
+            with open(self.training_path + '/args.json') as args_dict:
+                args_dict = json.load(args_dict,)
+            self.args = argparse.Namespace()
+            for (k, v) in args_dict.items():
+                vars(self.args)[k] = v
+
+            # Define array to hold old time snapshots and control inputs of the system
+            self.X = np.zeros((self.args.seq_length//2 + 1, 128, 256, 4), dtype=np.float32)
+            self.u = np.zeros((self.args.seq_length//2, self.args.action_dim), dtype=np.float32)
+
+            # Initialize predicted state
+            self.x_pred = np.zeros(self.args.code_dim)
+
+            # Run script to find desired attributes and store them
+            command = "python " + self.training_path + "/find_matrices.py " + self.training_path + " " + self.ckpt_name + " " + base_flow
+            subprocess.call(command.split())
+
+            # Load desired attributes from file
+            f = h5py.File('./matrices_misc.h5', 'r')
+            self.B = np.array(f['B'])
+            self.goal_state = np.array(f['goal_state'])
+
+        # Initial omega
+        intg.system.omega = 0
+
+        # MPI info
+        comm, rank, root = get_comm_rank_root()
+
+        # MPI rank responsible for each point and rank-indexed info
+        self._ptsrank = ptsrank = []
+        self._ptsinfo = ptsinfo = [[] for i in range(comm.size)]
+
+        # Physical location of the solution points
+        plocs = [p.swapaxes(1, 2) for p in intg.system.ele_ploc_upts]
+
+        # Load map from point to index
+        with open('loc_to_idx.json') as loc_to_idx:
+            loc_to_idx_str = json.load(loc_to_idx,)
+            self.loc_to_idx = dict()
+            for key in loc_to_idx_str:
+                self.loc_to_idx[int(key)] = loc_to_idx_str[key]
+
+
+        # Locate the closest solution points in our partition
+        closest = _closest_upts(intg.system.ele_types, plocs, self.pts)
+
+        # Process these points
+        for cp in closest:
+            # Reduce over the distance
+            _, mrank = comm.allreduce((cp[0], rank), op=get_mpi('minloc'))
+
+            # Store the rank responsible along with its info
+            ptsrank.append(mrank)
+            ptsinfo[mrank].append(
+                comm.bcast(cp[1:] if rank == mrank else None, root=mrank)
+            )
+
+    def _process_samples(self, samps):
+        samps = np.array(samps)
+
+        # If necessary then convert to primitive form
+        if self.fmt == 'primitive' and samps.size:
+            samps = self.elementscls.con_to_pri(samps.T, self.cfg)
+            samps = np.array(samps).T
+
+        return samps.tolist()
+
+    # Find A-matrix and initial code value from neural network
+    def _find_dynamics(self):
+        # Save X and u to file
+        f = h5py.File('./X_u.h5', 'w')
+        f['X'] = self.X
+        f['u'] = self.u
+        f.close()
+
+        # Run python script to find A matrix and initial state
+        command = "python " + self.training_path + "/find_dynamics.py " + self.training_path + " " + self.ckpt_name
+        subprocess.call(command.split())
+
+        # Load desired values from file and return
+        f = h5py.File('A_x0.h5', 'r')
+        A = np.array(f['A'])
+        x0 = np.array(f['x0'])
+
+        return A, x0
+
+    # Perform MPC optimization to find next input
+    # Following example from CVXPY documentation
+    def _find_mpc_input(self, A, B, x0):
+        # First define prediction horizon
+        T = 16
+
+        # Define variables
+        x = Variable(shape = (self.args.code_dim, T+1))
+        u = Variable(shape = (self.args.action_dim, T))
+
+        # Define costs for states and inputs
+        Q = np.eye(self.args.code_dim)
+        R = self.R*np.eye(self.args.action_dim)
+
+        # Construct and solve optimization problem
+        cost = 0
+        constr = []
+        for t in range(T):
+            cost += quad_form((x[:,t+1] - self.goal_state), Q) + quad_form(u[:,t], R)
+            constr += [x[:,t+1] == A*x[:,t] + (B*u[:,t])[:,0],
+                        norm(u[:,t], 'inf') <= self.u_max]
+
+        # Sum problem objectives and concatenate constraints
+        constr += [x[:,0] == x0]
+        prob = Problem(Minimize(cost),constr)
+        prob.solve()
+        
+        x1 = np.array([x.value[i, 1] for i in range(x.value.shape[0])])
+        try:
+            return u.value[0, 0] # Change if not scalar input
+        except:
+            return 0.0
+
+    def __call__(self, intg):
+        # Return if there is nothing to do for this step
+        if (intg.nacptsteps % self.nsteps):
+            return
+
+        # MPI info
+        comm, rank, root = get_comm_rank_root()
+
+        # Solution matrices indexed by element type
+        solns = dict(zip(intg.system.ele_types, intg.soln))
+
+        # Points we're responsible for sampling
+        ourpts = self._ptsinfo[comm.rank]
+
+        # Sample the solution matrices at these points
+        samples = [solns[et][ui, :, ei] for _, et, (ui, ei) in ourpts]
+        samples = self._process_samples(samples)
+
+        # Gather to the root rank to give a list of points per rank
+        samples = comm.gather(samples, root=root)
+
+        # If we're the root rank process the data
+        if rank == root:
+            data = []
+
+            # Collate
+            iters = [zip(pi, sp) for pi, sp in zip(self._ptsinfo, samples)]
+
+            for mrank in self._ptsrank:
+                # Unpack
+                (ploc, etype, idx), samp = next(iters[mrank])
+
+                # Determine the physical mesh rank
+                prank = intg.rallocs.mprankmap[mrank]
+
+                # Prepare the output row [[x, y], [rho, rhou, rhouv, E]]
+                row = [ploc, samp]
+
+                # Append
+                data.append(row)
+
+            # Define info for saving to file
+            list_of_files = glob.glob(self.save_dir + '/*')
+            if len(list_of_files) == 0:
+                file_num = 0
+            else:
+                latest_file = max(list_of_files, key=os.path.getctime)
+                file_num = int(latest_file[-7:-3])
+
+            # Save data in desired format
+            # Define freestream values for to be used for cylinder
+            rho = 1.0
+            P = 1.0
+            u = 0.236
+            v = 0.0
+            e = P/rho/0.4 + 0.5*(u**2 + v**2)
+            freestream = np.array([rho, rho*u, rho*v, e])
+            sol_data = np.zeros((128, 256, 4))
+            sol_data[:, :] = freestream
+            for i in range(len(self.loc_to_idx)):
+                idx1, idx2 = self.loc_to_idx[i]
+                sol_data[idx1, idx2] = data[i][1]
+
+            # Update running total of previous states
+            if self.perform_mpc: self.X = np.vstack((self.X[1:], np.expand_dims(sol_data, axis=0)))
+
+            # Initialize values
+            t = intg.tcurr
+            self.t_old = t
+            pred_error = 0.0
+
+            if self.set_omega == 0:
+                omega = 0.0
+            elif self.perform_mpc:
+                # Find model of system and determine optimal input with MPC
+                try:
+                    A, x0 = self._find_dynamics()
+                    if np.linalg.norm(self.X[0]) > 0.0:
+                        u0 = self.u[-1]
+                        omega = self._find_mpc_input(A, self.B, x0)
+                    else:
+                        omega = 0.0 # No input if insufficient data to construct dynamical model
+                except:
+                    print("Had an error in mpc -- setting omega to 0")
+                    omega = 0.0
+                self.u = np.concatenate((self.u[1:], np.expand_dims(np.array([omega]), axis=0)))
+            else:
+                # To generate training data
+                # Have no inputs for periods, otherwise sinusoidal
+                if t % 1000 > 900:
+                    omega = 0.0
+                else:
+                    freq = 2*np.pi * (t/1000)/500.0
+                    omega = 0.3*np.sin(freq*t)
+
+
+                # Proportional control
+                # location = 88 # re50
+                # gain = 0.4 # re50
+                # rho = sol_data[64, location, 0]
+                # rho_v = sol_data[64, location, 2]
+                # omega = gain*rho_v/rho
+
+
+            # Save data if desired
+            if self.save_data == 1:
+                # Save to h5 file
+                file_num += 1
+                filename = self.save_dir + '/sol_data_' + str(file_num).zfill(4) + '.h5'
+                f = h5py.File(filename, 'w')
+                f['sol_data'] = sol_data
+                f['control_input'] = omega
+                if self.perform_mpc: f['cost'] = np.linalg.norm(self.goal_state - x0)
+                f.close()
+        else:
+            omega = None
+
+        # Broadcast omega to all of the MPI ranks
+        intg.system.omega = float(comm.bcast(omega, root=root))
diff --git a/pyfr/solvers/baseadvecdiff/system.py b/pyfr/solvers/baseadvecdiff/system.py
index eff6eab..aab3b72 100644
--- a/pyfr/solvers/baseadvecdiff/system.py
+++ b/pyfr/solvers/baseadvecdiff/system.py
@@ -21,7 +21,7 @@ class BaseAdvectionDiffusionSystem(BaseAdvectionSystem):
         if ('iint', 'copy_fpts') in kernels:
             q1 << kernels['iint', 'copy_fpts']()
         q1 << kernels['iint', 'con_u']()
-        q1 << kernels['bcint', 'con_u'](t=t)
+        q1 << kernels['bcint', 'con_u'](t=t, omega=self.omega)
         if ('eles', 'shocksensor') in kernels:
             q1 << kernels['eles', 'shocksensor']()
             q1 << kernels['mpiint', 'artvisc_fpts_pack']()
@@ -49,7 +49,7 @@ class BaseAdvectionDiffusionSystem(BaseAdvectionSystem):
         q1 << kernels['eles', 'tdisf']()
         q1 << kernels['eles', 'tdivtpcorf']()
         q1 << kernels['iint', 'comm_flux']()
-        q1 << kernels['bcint', 'comm_flux'](t=t)
+        q1 << kernels['bcint', 'comm_flux'](t=t, omega=self.omega)
 
         q2 << kernels['mpiint', 'vect_fpts_send']()
         q2 << kernels['mpiint', 'vect_fpts_recv']()
diff --git a/pyfr/solvers/euler/kernels/bcs/char-riem-inv.mako b/pyfr/solvers/euler/kernels/bcs/char-riem-inv.mako
index 9e0d754..ed626af 100644
--- a/pyfr/solvers/euler/kernels/bcs/char-riem-inv.mako
+++ b/pyfr/solvers/euler/kernels/bcs/char-riem-inv.mako
@@ -4,7 +4,7 @@
 <% gmo = c['gamma'] - 1.0 %>
 <% gamma = c['gamma'] %>
 
-<%pyfr:macro name='bc_rsolve_state' params='ul, nl, ur, ploc, t'>
+<%pyfr:macro name='bc_rsolve_state' params='ul, nl, ur, ploc, t, omega'>
     fpdtype_t cs = sqrt(${gamma}*${c['p']}/${c['rho']});
     fpdtype_t s = ${c['p']}*pow(${c['rho']}, -${gamma});
     fpdtype_t ratio = cs*${2.0/gmo};
diff --git a/pyfr/solvers/navstokes/inters.py b/pyfr/solvers/navstokes/inters.py
index 801bd7e..80dfa59 100644
--- a/pyfr/solvers/navstokes/inters.py
+++ b/pyfr/solvers/navstokes/inters.py
@@ -105,11 +105,14 @@ class NavierStokesNoSlpIsotWallBCInters(NavierStokesBaseBCInters):
     type = 'no-slp-isot-wall'
     cflux_state = 'ghost'
 
-    def __init__(self, *args, **kwargs):
-        super().__init__(*args, **kwargs)
+    def __init__(self, be, lhs, elemap, cfgsect, cfg):
+        super().__init__(be, lhs, elemap, cfgsect, cfg)
 
-        self._tpl_c['cpTw'], = self._eval_opts(['cpTw'])
-        self._tpl_c['v'] = self._eval_opts('uvw'[:self.ndims], default='0')
+        tplc = self._exp_opts(
+            'uvw'[:self.ndims], lhs, default=dict(u='0', v='0', w='0')
+        )
+        tplc['cpTw'], = self._eval_opts(['cpTw'])
+        self._tpl_c.update(tplc)
 
 
 class NavierStokesNoSlpAdiaWallBCInters(NavierStokesBaseBCInters):
diff --git a/pyfr/solvers/navstokes/kernels/bccflux.mako b/pyfr/solvers/navstokes/kernels/bccflux.mako
index 03f63d7..c2c6e76 100644
--- a/pyfr/solvers/navstokes/kernels/bccflux.mako
+++ b/pyfr/solvers/navstokes/kernels/bccflux.mako
@@ -15,6 +15,7 @@
               nl='in fpdtype_t[${str(ndims)}]'
               magnl='in fpdtype_t'
               ploc='in fpdtype_t[${str(ndims)}]'
-              t='scalar fpdtype_t'>
-    ${pyfr.expand('bc_common_flux_state', 'ul', 'gradul', 'artviscl', 'nl', 'magnl', 'ploc', 't')};
+              t='scalar fpdtype_t'
+              omega='scalar fpdtype_t'>
+    ${pyfr.expand('bc_common_flux_state', 'ul', 'gradul', 'artviscl', 'nl', 'magnl', 'ploc', 't', 'omega')};
 </%pyfr:kernel>
diff --git a/pyfr/solvers/navstokes/kernels/bcconu.mako b/pyfr/solvers/navstokes/kernels/bcconu.mako
index 97a0d92..b3416d3 100644
--- a/pyfr/solvers/navstokes/kernels/bcconu.mako
+++ b/pyfr/solvers/navstokes/kernels/bcconu.mako
@@ -9,6 +9,7 @@
               ulout='out view fpdtype_t[${str(nvars)}]'
               nlin='in fpdtype_t[${str(ndims)}]'
               ploc='in fpdtype_t[${str(ndims)}]'
-              t='scalar fpdtype_t'>
-    ${pyfr.expand('bc_ldg_state', 'ulin', 'nlin', 'ulout', 'ploc', 't')};
+              t='scalar fpdtype_t'
+              omega='scalar fpdtype_t'>
+    ${pyfr.expand('bc_ldg_state', 'ulin', 'nlin', 'ulout', 'ploc', 't', 'omega')};
 </%pyfr:kernel>
diff --git a/pyfr/solvers/navstokes/kernels/bcs/ghost.mako b/pyfr/solvers/navstokes/kernels/bcs/ghost.mako
index abe76b0..6a5ac15 100644
--- a/pyfr/solvers/navstokes/kernels/bcs/ghost.mako
+++ b/pyfr/solvers/navstokes/kernels/bcs/ghost.mako
@@ -6,10 +6,10 @@
 
 <% tau = c['ldg-tau'] %>
 
-<%pyfr:macro name='bc_common_flux_state' params='ul, gradul, artviscl, nl, magnl, ploc, t'>
+<%pyfr:macro name='bc_common_flux_state' params='ul, gradul, artviscl, nl, magnl, ploc, t, omega'>
     // Viscous states
     fpdtype_t ur[${nvars}], gradur[${ndims}][${nvars}];
-    ${pyfr.expand('bc_ldg_state', 'ul', 'nl', 'ur', 'ploc', 't')};
+    ${pyfr.expand('bc_ldg_state', 'ul', 'nl', 'ur', 'ploc', 't', 'omega')};
     ${pyfr.expand('bc_ldg_grad_state', 'ul', 'nl', 'gradul', 'gradur')};
 
     fpdtype_t fvr[${ndims}][${nvars}] = {{0}};
@@ -17,7 +17,7 @@
     ${pyfr.expand('artificial_viscosity_add', 'gradur', 'fvr', 'artviscl')};
 
     // Inviscid (Riemann solve) state
-    ${pyfr.expand('bc_rsolve_state', 'ul', 'nl', 'ur', 'ploc', 't')};
+    ${pyfr.expand('bc_rsolve_state', 'ul', 'nl', 'ur', 'ploc', 't', 'omega')};
 
     // Perform the Riemann solve
     fpdtype_t ficomm[${nvars}], fvcomm;
diff --git a/pyfr/solvers/navstokes/kernels/bcs/no-slp-isot-wall.mako b/pyfr/solvers/navstokes/kernels/bcs/no-slp-isot-wall.mako
index 6bf7525..6b24363 100644
--- a/pyfr/solvers/navstokes/kernels/bcs/no-slp-isot-wall.mako
+++ b/pyfr/solvers/navstokes/kernels/bcs/no-slp-isot-wall.mako
@@ -2,19 +2,19 @@
 <%namespace module='pyfr.backends.base.makoutil' name='pyfr'/>
 <%include file='pyfr.solvers.navstokes.kernels.bcs.common'/>
 
-<%pyfr:macro name='bc_rsolve_state' params='ul, nl, ur, ploc, t'>
+<%pyfr:macro name='bc_rsolve_state' params='ul, nl, ur, ploc, t, omega'>
     ur[0] = ul[0];
-% for i, v in enumerate(c['v']):
-    ur[${i + 1}] = -ul[${i + 1}] + ${2*v}*ul[0];
+% for i, v in enumerate('uvw'[:ndims]):
+    ur[${i + 1}] = -ul[${i + 1}] + 2*${c[v]}*ul[0];
 % endfor
     ur[${nvars - 1}] = ${c['cpTw']/c['gamma']}*ur[0]
                      + 0.5*(1.0/ur[0])*${pyfr.dot('ur[{i}]', i=(1, ndims + 1))};
 </%pyfr:macro>
 
-<%pyfr:macro name='bc_ldg_state' params='ul, nl, ur, ploc, t'>
+<%pyfr:macro name='bc_ldg_state' params='ul, nl, ur, ploc, t, omega'>
     ur[0] = ul[0];
-% for i, v in enumerate(c['v']):
-    ur[${i + 1}] = ${v}*ul[0];
+% for i, v in enumerate('uvw'[:ndims]):
+    ur[${i + 1}] = ${c[v]}*ul[0];
 % endfor
     ur[${nvars - 1}] = ${c['cpTw']/c['gamma']}*ur[0]
                      + 0.5*(1.0/ur[0])*${pyfr.dot('ur[{i}]', i=(1, ndims + 1))};
